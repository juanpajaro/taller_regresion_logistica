#!/usr/bin/env python3
"""
Evaluaci√≥n espec√≠fica de la funci√≥n gradiente_descendente
"""

import numpy as np
import sys
import os

# Configurar el entorno
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from taller import gradiente_descendente, sigmoid

def test_gradiente_descendente():
    """Eval√∫a la funci√≥n gradiente_descendente y verifica que coincida con los valores esperados"""
    
    print("="*60)
    print("EVALUACI√ìN DE LA FUNCI√ìN GRADIENTE_DESCENDENTE")
    print("="*60)
    
    # Crear datos sint√©ticos exactos para reproducir los resultados esperados
    # Usar semilla espec√≠fica para garantizar reproducibilidad
    np.random.seed(42)
    m = 100  # n√∫mero de ejemplos
    
    # Crear caracter√≠sticas (sesgo + 2 caracter√≠sticas)
    X = np.column_stack([
        np.ones(m),  # sesgo
        np.random.randn(m),  # caracter√≠stica 1
        np.random.randn(m)   # caracter√≠stica 2
    ])
    
    # Crear etiquetas con cierta l√≥gica para obtener la distribuci√≥n esperada
    y_real = (X[:, 1] + X[:, 2] > 0).astype(float).reshape(-1, 1)
    
    # Verificar que tenemos la distribuci√≥n correcta (47 positivas, 53 negativas)
    num_positivas = np.sum(y_real)
    num_negativas = m - num_positivas
    
    print(f"Datos generados: {m} ejemplos, {X.shape[1]} caracter√≠sticas")
    print(f"Distribuci√≥n de etiquetas: {num_positivas} positivas, {num_negativas} negativas")
    
    # Par√°metros de entrenamiento
    theta_inicial = np.zeros((3, 1))
    alpha = 0.01
    iteraciones = 1000
    
    print(f"\nPar√°metros de entrenamiento:")
    print(f"  Theta inicial: {theta_inicial.flatten()}")
    print(f"  Tasa de aprendizaje: {alpha}")
    print(f"  Iteraciones: {iteraciones}")
    
    # Entrenar modelo
    costo_final, theta_final = gradiente_descendente(X, y_real, theta_inicial, alpha, iteraciones)
    
    print(f"\nResultados del entrenamiento:")
    print(f"  Costo final: {costo_final:.6f}")
    print(f"  Theta final: {theta_final.flatten()}")
    
    # Evaluar predicciones
    z = np.dot(X, theta_final)
    predicciones = sigmoid(z)
    predicciones_binarias = (predicciones > 0.5).astype(float)
    
    accuracy = np.mean(predicciones_binarias == y_real)
    print(f"  Precisi√≥n en datos de entrenamiento: {accuracy:.4f}")
    
    # Valores esperados
    costo_esperado = 0.323893
    theta_esperado = np.array([-0.0678694, 1.10602115, 1.4296585])
    accuracy_esperado = 0.9600
    
    print("\n" + "="*60)
    print("VERIFICACI√ìN DE RESULTADOS")
    print("="*60)
    
    # Verificar costo final (con tolerancia)
    costo_correcto = abs(costo_final - costo_esperado) < 0.01
    print(f"Costo final: {costo_final:.6f} (esperado: {costo_esperado:.6f}) {'‚úì' if costo_correcto else '‚úó'}")
    
    # Verificar theta (con tolerancia para cada componente)
    theta_correcto = True
    print("Verificaci√≥n de theta:")
    for i, (actual, esperado) in enumerate(zip(theta_final.flatten(), theta_esperado)):
        componente_correcto = abs(actual - esperado) < 0.1
        if not componente_correcto:
            theta_correcto = False
        print(f"  Œ∏[{i}]: {actual:.7f} (esperado: {esperado:.7f}) {'‚úì' if componente_correcto else '‚úó'}")
    
    # Verificar accuracy
    accuracy_correcto = abs(accuracy - accuracy_esperado) < 0.05
    print(f"Precisi√≥n: {accuracy:.4f} (esperado: {accuracy_esperado:.4f}) {'‚úì' if accuracy_correcto else '‚úó'}")
    
    # Resultado final
    print("\n" + "="*60)
    print("RESULTADO FINAL")
    print("="*60)
    
    todos_correctos = costo_correcto and theta_correcto and accuracy_correcto
    
    if todos_correctos:
        print("‚úì La funci√≥n gradiente_descendente funciona CORRECTAMENTE")
        print("‚úì Todos los valores est√°n dentro del rango esperado")
    else:
        print("‚úó La funci√≥n gradiente_descendente NO produce los valores esperados")
        if not costo_correcto:
            print(f"‚úó Costo final fuera del rango: diferencia = {abs(costo_final - costo_esperado):.6f}")
        if not theta_correcto:
            print("‚úó Algunos par√°metros theta est√°n fuera del rango esperado")
        if not accuracy_correcto:
            print(f"‚úó Precisi√≥n fuera del rango: diferencia = {abs(accuracy - accuracy_esperado):.4f}")
    
    # Informaci√≥n adicional sobre el entrenamiento
    print(f"\nINFORMACI√ìN ADICIONAL:")
    print(f"  Reducci√≥n del costo durante entrenamiento: Calculado impl√≠citamente")
    print(f"  Convergencia: {'S√≠' if costo_final < 0.5 else 'Parcial'}")
    print(f"  Ejemplos clasificados correctamente: {int(accuracy * m)}/{m}")
    
    return todos_correctos

def test_reproducibilidad():
    """Prueba adicional para verificar reproducibilidad"""
    print("\n" + "="*60)
    print("PRUEBA DE REPRODUCIBILIDAD")
    print("="*60)
    
    # Ejecutar el mismo experimento dos veces
    resultados = []
    
    for i in range(2):
        np.random.seed(42)  # Misma semilla
        m = 100
        X = np.column_stack([np.ones(m), np.random.randn(m), np.random.randn(m)])
        y = (X[:, 1] + X[:, 2] > 0).astype(float).reshape(-1, 1)
        
        costo, theta = gradiente_descendente(X, y, np.zeros((3, 1)), 0.01, 1000)
        resultados.append((costo, theta.flatten()))
        print(f"Ejecuci√≥n {i+1}: Costo = {costo:.6f}, Theta = {theta.flatten()}")
    
    # Verificar que los resultados son id√©nticos
    costo1, theta1 = resultados[0]
    costo2, theta2 = resultados[1]
    
    reproducible = (abs(costo1 - costo2) < 1e-10) and np.allclose(theta1, theta2, atol=1e-10)
    print(f"\n¬øResultados reproducibles? {'‚úì S√≠' if reproducible else '‚úó No'}")
    
    return reproducible

if __name__ == "__main__":
    print("PRUEBAS DE LA FUNCI√ìN GRADIENTE_DESCENDENTE")
    print("=" * 80)
    
    # Ejecutar prueba principal
    resultado_principal = test_gradiente_descendente()
    
    # Ejecutar prueba de reproducibilidad
    resultado_reproducibilidad = test_reproducibilidad()
    
    print("\n" + "="*80)
    print("RESUMEN FINAL")
    print("="*80)
    
    if resultado_principal and resultado_reproducibilidad:
        print("üéâ TODAS LAS PRUEBAS PASARON EXITOSAMENTE")
        print("‚úì La funci√≥n gradiente_descendente est√° funcionando correctamente")
        print("‚úì Los resultados son reproducibles")
    else:
        print("‚ö†Ô∏è ALGUNAS PRUEBAS FALLARON")
        if not resultado_principal:
            print("‚úó La prueba principal fall√≥")
        if not resultado_reproducibilidad:
            print("‚úó La prueba de reproducibilidad fall√≥")
    
    print("="*80)
